{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment 2_ Replicating SotA with BLM data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOkrKN9r450y8/XC7BknVf4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ab2207/Academic-Projects-Data-Analytics/blob/main/Masters%20Thesis%20Experiment%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDPtCWYuOO2w"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPyg-9Uq8RDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2546ee-5dbd-4888-b8cf-63f727956e57"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0aYT1Od9ljV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f83bccb3-f75a-4af3-acc7-82bec4344874"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import string \n",
        "string.punctuation\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')\n",
        "import re\n",
        "import unicodedata"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FbZFGQp9ll_"
      },
      "source": [
        "data = pd.read_csv(\"/content/gdrive/My Drive/BLM_Tweets_1M.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQL0gifS9lrO"
      },
      "source": [
        "def tweets_cleaning(text):\n",
        "    lowercase = text.lower()\n",
        "    punc_removal = [char for char in lowercase if char not in string.punctuation]\n",
        "    punc_removal_joined = ''.join(punc_removal)\n",
        "    url_removal = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', punc_removal_joined, flags=re.MULTILINE)\n",
        "    emoji_removal = url_removal.encode('ascii', 'ignore').decode('ascii')\n",
        "    stopwords_removal = [word for word in emoji_removal.split() if word not in stopwords.words('english')]\n",
        "    return stopwords_removal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYV4OY3A9lun"
      },
      "source": [
        "data['cleaned_text'] = data['text'].apply(tweets_cleaning).astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHG5dWGx-B0b"
      },
      "source": [
        "from textblob import TextBlob\n",
        "data['polarity'] = data['cleaned_text'].apply(lambda x: TextBlob(x).sentiment.polarity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO8OS_A9_Myk"
      },
      "source": [
        "conditionList = [\n",
        "                 data['polarity'] < 0,\n",
        "                 data['polarity'] >= 0]\n",
        "choiceList = ['0', '1']\n",
        "data['target'] = np.select(conditionList, choiceList, default='no_label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHZMPOv79lz5"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cLgUHPD9l22"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token = \"<OOV>\")\n",
        "tokenizer.fit_on_texts(data['cleaned_text'].values)\n",
        "\n",
        "word_index = tokenizer.word_index #word tokenizing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeYlxmNl9l5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7c539b-4d0e-46e5-8dcb-221d7366d3e9"
      },
      "source": [
        "vocab_size = len(word_index) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "924810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbow2zuq9l_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3398631a-c142-423b-ec1a-c7131d1a98d5"
      },
      "source": [
        "train_sentence_tokenizing = tokenizer.texts_to_sequences(data['cleaned_text'].values)\n",
        "X = pad_sequences(train_sentence_tokenizing, padding = \"post\", truncating = \"post\", maxlen= 26)\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    2 45225 70438 ...     0     0     0]\n",
            " [ 7817  1520     2 ...     0     0     0]\n",
            " [  124  5478 91399 ...     0     0     0]\n",
            " ...\n",
            " [30034     2    56 ...     0     0     0]\n",
            " [    6     7  1245 ...     0     0     0]\n",
            " [ 1823  1238    29 ...     0     0     0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VB1-AyJ9mCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ee1070-d269-4a8b-d43e-22ce9b4e8474"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('/content/gdrive/My Drive/glove.twitter.27B.200d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 1193514 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlzNgxyi9mFq"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 200))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hkBYD7S9mLY"
      },
      "source": [
        "y = pd.get_dummies(data['target']).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20r4M9Wp9mOi"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout, Activation, Input, Flatten, Bidirectional\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixJylDFy9mR8"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1234, test_size = 0.20, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2i6hMuz9mUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8cacf7-bcc0-41c9-be7d-7d30e93d97a4"
      },
      "source": [
        "embed_dim = 200\n",
        "lstm_out = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embed_dim,input_length = X.shape[1], weights=[embedding_matrix],trainable=False))\n",
        "model.add(LSTM(lstm_out, return_sequences=True))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(lstm_out))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 26, 200)           184962000 \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 26, 128)           168448    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 26, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 258       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 185,262,290\n",
            "Trainable params: 300,290\n",
            "Non-trainable params: 184,962,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZr4UmfJ9maw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed4f82d-39c5-49d7-8d64-9ef8048efa36"
      },
      "source": [
        "batch_size = 320\n",
        "model.fit(X_train, y_train, epochs = 5, verbose = 1, validation_data=(X_test, y_test), batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "2508/2508 [==============================] - 31s 12ms/step - loss: 0.4817 - accuracy: 0.8141 - val_loss: 0.4800 - val_accuracy: 0.8144\n",
            "Epoch 2/5\n",
            "2508/2508 [==============================] - 31s 12ms/step - loss: 0.4806 - accuracy: 0.8144 - val_loss: 0.4803 - val_accuracy: 0.8144\n",
            "Epoch 3/5\n",
            "2508/2508 [==============================] - 31s 12ms/step - loss: 0.4804 - accuracy: 0.8144 - val_loss: 0.4799 - val_accuracy: 0.8144\n",
            "Epoch 4/5\n",
            "2508/2508 [==============================] - 31s 12ms/step - loss: 0.4802 - accuracy: 0.8144 - val_loss: 0.4799 - val_accuracy: 0.8144\n",
            "Epoch 5/5\n",
            "2508/2508 [==============================] - 31s 13ms/step - loss: 0.4801 - accuracy: 0.8144 - val_loss: 0.4799 - val_accuracy: 0.8144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f42e00a5080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDlcwBat9nAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a3eed5-1131-4b6f-8004-fa6493025329"
      },
      "source": [
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 81.435239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_s_Vm4Q9nDh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzZnOQtg9nGB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLhE2WNV9nI7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67LZfvgM9nL8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCTUwag39nOn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx2oCgo69nUI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxvoGdRJ9nWv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}